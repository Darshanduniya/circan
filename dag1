from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.ssh_operator import SSHOperator
from airflow.operators.python_operator import PythonOperator

# Default arguments for the DAG
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2024, 1, 1),
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# Instantiate the DAG
dag = DAG(
    'example_ssh_operator_with_xcom',
    default_args=default_args,
    description='An example DAG using SSHOperator with XCom',
    schedule_interval=timedelta(days=1),
)

# Task 1: SSHOperator to run a remote command
task_ssh = SSHOperator(
    task_id='run_remote_command',
    ssh_conn_id='your_ssh_conn_id',  # specify your SSH connection ID
    command='echo "Hello, Airflow!"',  # replace this with your remote command
    dag=dag,
)

# Task 2: PythonOperator to process the output of the remote command and push it to XCom
def process_remote_output(**kwargs):
    ti = kwargs['ti']
    remote_output = ti.xcom_pull(task_ids='run_remote_command')
    processed_output = f"Processed: {remote_output}"
    print(processed_output)
    return processed_output

task_process_output = PythonOperator(
    task_id='process_remote_output',
    python_callable=process_remote_output,
    provide_context=True,
    dag=dag,
)

# Set task dependencies
task_ssh >> task_process_output

# Optionally, you can define more tasks and their dependencies as needed

if __name__ == "__main__":
    dag.cli()
